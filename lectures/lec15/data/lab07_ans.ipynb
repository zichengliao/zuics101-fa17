{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `lab07`—Probabilistic Language Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❖ Objectives\n",
    "\n",
    "-   Work with data in files.\n",
    "-   Learn the standard pipeline of data analysis:  data cleaning and preparation, data processing, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "**Pair Programming**\n",
    "<br />\n",
    "Since this lab is fairly involved, we encourage you to work in pairs *at a single machine*.  You and your partner will consult, and should occasionally trade off so that the time at the keyboard is roughly equal.  At the end, when you report collaborators, please report the names and NetIDs of all partners in this lab exercise.  (In exceptional cases, such as the room layout, trios are permitted.)\n",
    "</div>\n",
    "\n",
    "A random sampling of English text produces approximately the following letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-eng.png\" width=\"80%;\"/>\n",
    "\n",
    "whereas Latin has the letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-lat.png\" width=\"80%;\"/>\n",
    "\n",
    "and Welsh has the letter frequency distribution:\n",
    "\n",
    "<img src=\"./img/freq-cym.png\" width=\"80%;\"/>\n",
    "\n",
    "Each language tends to have a unique \"fingerprint\" because of the relative frequency of letters and sounds.  Such letter frequency information could be used, for instance, to determine how much type should be ordered for a letterpress, or how many tiles should be included in a country-specific version of Scrabble.\n",
    "\n",
    "Today you will use this fingerprint to assign rough probabilities to the likely language of a given text sample in an unknown language.  (This is similar to what [Google Translate](https://translate.google.com/) does when it auto-detects the language of a text sample, except that it uses whole words instead of letter frequencies to make its guess.)\n",
    "\n",
    "There are three steps in the data processing pipeline for you to complete today:\n",
    "\n",
    "1.  Count the frequency of each letter in the text sample.  Then divide the resulting list of frequencies by the total number of letters and get the normalized letter frequency distribution.\n",
    "1.  Load the reference language frequencies.\n",
    "1.  Predict the most likely language based on comparing the text letter frequency with each of the reference frequencies.\n",
    "\n",
    "<br/>\n",
    "<div class=\"alert alert-info\">\n",
    "We will restrict ourselves to the 26 letters of the basic Latin alphabet, disallowing diacritics ('naïve'→'naive'), accents ('recherché'→'recherche'), and nonbasic letters ('Skjærvø'→'Skjarvo').  (If you are a native speaker of another language, we sincerely apologize for this rank philistinism.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Calculate the normalized letter frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate letter frequencies, you need a list of letters and the string in all upper-case letters.  To avoid confusion, we will rename this built-in string `ascii_uppercase` as `alphabet` when we `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_uppercase as alphabet\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JACKDAWS LOVE MY BIG SPHINX OF QUARTZ.\n"
     ]
    }
   ],
   "source": [
    "# Our example text.\n",
    "text = 'Jackdaws love my big Sphinx of Quartz.'\n",
    "text = text.upper()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an empty frequency dictionary `letter_freq`.  Loop over each letter of the `alphabet` and `count` the number of times each letter occurs in `text`.  Add this count to `letter_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 3,\n",
       " 'B': 1,\n",
       " 'C': 1,\n",
       " 'D': 1,\n",
       " 'E': 1,\n",
       " 'F': 1,\n",
       " 'G': 1,\n",
       " 'H': 1,\n",
       " 'I': 2,\n",
       " 'J': 1,\n",
       " 'K': 1,\n",
       " 'L': 1,\n",
       " 'M': 1,\n",
       " 'N': 1,\n",
       " 'O': 2,\n",
       " 'P': 1,\n",
       " 'Q': 1,\n",
       " 'R': 1,\n",
       " 'S': 2,\n",
       " 'T': 1,\n",
       " 'U': 1,\n",
       " 'V': 1,\n",
       " 'W': 1,\n",
       " 'X': 1,\n",
       " 'Y': 1,\n",
       " 'Z': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_freq = {}  # a blank dictionary\n",
    "\n",
    "# Loop over the alphabet.\n",
    "for letter in alphabet:\n",
    "    # For each letter, get the number of times it occurs in the string `text`.\n",
    "    letter_count = text.count(letter)\n",
    "    letter_freq[letter] = letter_count\n",
    "\n",
    "letter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to normalize the values.  To do this, you need to calculate the total number of letters in `text` (letters, NOT whitespace or punctuation).  Since this is a bit involved, the following lines of code will give you a copy of `text` without whitespace or punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\t\\n\\x0b\\x0c\\r ', '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', '0123456789')\n",
      "JACKDAWSLOVEMYBIGSPHINXOFQUARTZ\n"
     ]
    }
   ],
   "source": [
    "# These are built-in collections of characters, useful for just this sort of filtering.\n",
    "from string import whitespace, punctuation, digits\n",
    "print(whitespace, punctuation, digits)\n",
    "for character in whitespace+punctuation+digits:\n",
    "    text = text.replace(character, '')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set each frequency value in the dictionary to its normalized value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.0967741935483871,\n",
       " 'B': 0.03225806451612903,\n",
       " 'C': 0.03225806451612903,\n",
       " 'D': 0.03225806451612903,\n",
       " 'E': 0.03225806451612903,\n",
       " 'F': 0.03225806451612903,\n",
       " 'G': 0.03225806451612903,\n",
       " 'H': 0.03225806451612903,\n",
       " 'I': 0.06451612903225806,\n",
       " 'J': 0.03225806451612903,\n",
       " 'K': 0.03225806451612903,\n",
       " 'L': 0.03225806451612903,\n",
       " 'M': 0.03225806451612903,\n",
       " 'N': 0.03225806451612903,\n",
       " 'O': 0.06451612903225806,\n",
       " 'P': 0.03225806451612903,\n",
       " 'Q': 0.03225806451612903,\n",
       " 'R': 0.03225806451612903,\n",
       " 'S': 0.06451612903225806,\n",
       " 'T': 0.03225806451612903,\n",
       " 'U': 0.03225806451612903,\n",
       " 'V': 0.03225806451612903,\n",
       " 'W': 0.03225806451612903,\n",
       " 'X': 0.03225806451612903,\n",
       " 'Y': 0.03225806451612903,\n",
       " 'Z': 0.03225806451612903}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in letter_freq.keys():\n",
    "    letter_freq[key] = letter_freq[key] * 1.0 / len(text)\n",
    "letter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#FF8C00\">Exercises</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will turn the above process into a general function to process a string into its letter frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `calc_freq` which accepts a string `text`.  `calc_freq` should `return` a dictionary containing the normalized frequency by letter.\n",
    "    \n",
    "    You should use the above process just outlined to write this function.\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "When diagnosing the behavior of your code, we encourage you to use `print` statements freely.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "calc_freq",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "from string import whitespace, punctuation, digits\n",
    "from string import ascii_uppercase as alphabet\n",
    "\n",
    "def calc_freq(text):\n",
    "    # Create an empty frequency dictionary letter_freq.\n",
    "    letter_freq = {}\n",
    "    \n",
    "    # Make text upper-case.\n",
    "    ## YOU WRITE THIS LINE\n",
    "    text = text.upper()\n",
    "    \n",
    "    # Loop over each letter of the alphabet:\n",
    "    for letter in alphabet:\n",
    "        # Count the number of times each letter occurs in text.\n",
    "        letter_freq[letter] = text.count(letter)\n",
    "    \n",
    "    # Make a copy of text without non-alphabet characters.\n",
    "    from string import whitespace, punctuation, digits\n",
    "    for character in whitespace+punctuation+digits:\n",
    "        text = text.replace(character, '')\n",
    "    \n",
    "    # Normalize the frequencies and put the results back into letter_freq.\n",
    "    for key in letter_freq.keys():\n",
    "        letter_freq[key] = letter_freq[key] *1.0 / len(text)\n",
    "    \n",
    "    # Finally, return the dict letter_freq.\n",
    "    return letter_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.065625,\n",
       " 'B': 0.00625,\n",
       " 'C': 0.025,\n",
       " 'D': 0.05,\n",
       " 'E': 0.10625,\n",
       " 'F': 0.03125,\n",
       " 'G': 0.025,\n",
       " 'H': 0.071875,\n",
       " 'I': 0.078125,\n",
       " 'J': 0.0,\n",
       " 'K': 0.00625,\n",
       " 'L': 0.0125,\n",
       " 'M': 0.028125,\n",
       " 'N': 0.109375,\n",
       " 'O': 0.065625,\n",
       " 'P': 0.0125,\n",
       " 'Q': 0.0,\n",
       " 'R': 0.0625,\n",
       " 'S': 0.075,\n",
       " 'T': 0.10625,\n",
       " 'U': 0.040625,\n",
       " 'V': 0.00625,\n",
       " 'W': 0.009375,\n",
       " 'X': 0.0,\n",
       " 'Y': 0.00625,\n",
       " 'Z': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any sample text, but the following is provided for convenience.\n",
    "text = \"\"\"Neither the naked hand nor the understanding left to itself can effect much. It is by instruments and helps that the work is done,\n",
    "which are as much wanted for the understanding as for the hand. And as the instruments of the hand either give motion or guide it, so the\n",
    "instruments of the mind supply either suggestions for the understanding or cautions.  (Francis Bacon, Novum Organon, Aphorism II)\"\"\"\n",
    "calc_freq(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_freq-test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_text1 = \"\"\"The study of nature with a view to works is engaged in by the mechanic, the mathematician, the physician, the alchemist, and\n",
    "the magician; but by all (as things now are) with slight endeavor and scanty success.  (Francis Bacon, Novum Organon, Aphorism V)\"\"\"\n",
    "result_text1 = calc_freq(test_text1)\n",
    "assert isclose(result_text1['T'], 0.09045226130653267) and \\\n",
    "       isclose(result_text1['Q'], 0.0) and \\\n",
    "       isclose(result_text1['Y'], 0.0251256281407035)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "calc_freq-test2",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "test_text2 = \"\"\"In order to penetrate into the inner and further recesses of nature, it is necessary that both notions and axioms be derived\n",
    "from things by a more sure and guarded way, and that a method of intellectual operation be introduced altogether better and more certain.\n",
    "(Francis Bacon, Novum Organon, Aphorism XVIII)\"\"\"\n",
    "result_text2 = calc_freq(test_text2)\n",
    "assert isclose(result_text2['K'], 0.0) and \\\n",
    "       isclose(result_text2['N'], 0.09523809523809523) and \\\n",
    "       isclose(result_text2['L'], 0.015873015873015872)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Load the reference language frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous labs, some of the data we are interested in analyzing are stored in files.  Each language has a characteristic pattern of letter frequencies stored in the `./lang/` directory of `lab7`.  Reference frequencies for the following languages are available.  (These frequencies are derived from the work of Stefan Trost<sup>[[Trost2015](http://www.sttmedia.com/characterfrequencies)]</sup> and used with his permission.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afrikaans.txt',\n",
       " 'catalan.txt',\n",
       " 'danish.txt',\n",
       " 'english.txt',\n",
       " 'finnish.txt',\n",
       " 'french.txt',\n",
       " 'german.txt',\n",
       " 'latin.txt',\n",
       " 'polish.txt',\n",
       " 'portuguese.txt',\n",
       " 'spanish.txt',\n",
       " 'welsh.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "listdir('./lang/')  # this function shows us what is located in a given directory (as a list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the reference language frequencies, you will first write a function `load_ref` to load a given language reference file.  You will write a function `load_languages` which uses `load_ref` with a list of file names to create a `dict` of all of the language frequencies available.\n",
    "\n",
    "Take a look at the file format of `danish`:\n",
    "    \n",
    "    A,8.27%\n",
    "    B,1.42%\n",
    "    C,0.45%\n",
    "    ...\n",
    "\n",
    "If you wanted to read this into a dictionary, you could take each line and split it by the comma.\n",
    "\n",
    "Since you want to include the second part as a `float`, you need to convert it.  Try this out directly (but it will *fail*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.27'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDict = {}\n",
    "#testDict['A'] = float('8.27%')\n",
    "' 8.27%'.strip().strip('%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "The problem is that Python doesn't know if the percent sign in the string is supposed to be a string format marker or actually a percent sign, so it doesn't correctly parse this string into a `float`.\n",
    "</div>\n",
    "\n",
    "<h4 style=\"color:#FF8C00\">Exercises</h4>\n",
    "\n",
    "-  In order to convert a string of a percent value into a float, compose a function `p2f` (short for `percentToFloat`) which accepts a string `value`.  `p2f` `strip`s the percent sign off of the string `value`, converts this to a `float`, and then divides by `100` and `return`s the result.  (Python provides a function `round` which you may elect to use here to simplify the result, but this is not required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2f",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def p2f(value):\n",
    "    # Strip any whitespace and then strip the percent sign off of value.\n",
    "    ## YOU WRITE THIS\n",
    "    value = value.strip().strip('%')\n",
    "    \n",
    "    # Convert the result to a float and divide by 100.\n",
    "    result = float(value)/100.0 ## YOU WRITE THIS\n",
    "    \n",
    "    # Finally, return the result.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055999999999999994"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any sample value, but the following is provided for convenience.\n",
    "value = \"5.6%\"\n",
    "p2f(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p2f-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "assert isclose(p2f('1.79%'), 0.0179)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to add to the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict = {}\n",
    "testDict['A'] = p2f('8.27%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#FF8C00\">Exercises</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `load_ref` which accepts a string `language`.  `load_ref` should `return` a `dict` containing the reference language letter frequencies stored in the file `./lang/language`, where `language` will be replaced by `danish`, `catalan`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', '8.27%')\n"
     ]
    }
   ],
   "source": [
    "a,b = 'A,8.27%'.split(',')\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load_ref",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def load_ref(language):\n",
    "    # Create an empty dictionary called `languages`.\n",
    "    languages = {}\n",
    "    \n",
    "    # Open the language file, read the data out, and close the file.\n",
    "    ## YOU WRITE THIS BLOCK (check lab6 if you need a refresher)\n",
    "    ## Keep in mind the differences between read(), readlines(), and read().splitlines()\n",
    "    file = open('./lang/'+language+'.txt', 'r')\n",
    "    data = file.read().splitlines()\n",
    "    file.close()\n",
    "    for line in data:\n",
    "        letter,frequency = line.split(',')\n",
    "        languages[letter] = p2f(frequency)\n",
    "    # Loop over each line in the data.\n",
    "    ## YOU WRITE THIS BLOCK\n",
    "        # Split each line at the comma.  The first part should be assigned to a variable `letter`, the second part to a variable `frequency`.\n",
    "        ## YOU WRITE THIS LINE\n",
    "    \n",
    "        # Add the second part (the frequency) to the dictionary as the value (converted to a float)\n",
    "        # with the first part (the letter) as the key.  MAKE SURE THE KEY IS UPPER-CASE!\n",
    "        #languages[letter] = p2f(frequency)\n",
    "    \n",
    "    # Finally, return the dict `languages`.\n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.061200000000000004,\n",
       " 'B': 0.0196,\n",
       " 'C': 0.0316,\n",
       " 'D': 0.049800000000000004,\n",
       " 'E': 0.1693,\n",
       " 'F': 0.0149,\n",
       " 'G': 0.0302,\n",
       " 'H': 0.049800000000000004,\n",
       " 'I': 0.0802,\n",
       " 'J': 0.0024,\n",
       " 'K': 0.0132,\n",
       " 'L': 0.036000000000000004,\n",
       " 'M': 0.0255,\n",
       " 'N': 0.10529999999999999,\n",
       " 'O': 0.0254,\n",
       " 'P': 0.0067,\n",
       " 'Q': 0.0002,\n",
       " 'R': 0.0689,\n",
       " 'S': 0.0716,\n",
       " 'T': 0.0579,\n",
       " 'U': 0.044800000000000006,\n",
       " 'V': 0.0084,\n",
       " 'W': 0.0178,\n",
       " 'X': 0.0005,\n",
       " 'Y': 0.0005,\n",
       " 'Z': 0.0121}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code here.  You may edit this cell, and you may use any language listed above, but the following is provided for convenience.\n",
    "language = 'german'\n",
    "load_ref(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_ref-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "language = 'english'\n",
    "test_ref = load_ref(language)\n",
    "assert isclose(test_ref['A'], 0.0834)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to write a function `load_languages` which accepts a list of languages and creates a dictionary for each using `load_ref`.  Then all of these dictionaries will be added to an overall dictionary, by language.  That is, `master` will look something like this:\n",
    "\n",
    "        `master` is a dictionary with keys:\n",
    "            'afrikaans' -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "            'catalan'   -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "            'danish'    -> (a dictionary with keys:\n",
    "                                  letter -> frequency)\n",
    "\n",
    "Specifically,\n",
    "    \n",
    "    master['afrikaans']  # returns a dict containing the reference language frequencies for Afrikaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to get a list of available language files.  You can then open each of them, reading them into a dictionary using `load_ref`.\n",
    "\n",
    "While we could just list these out and do it manually, that's a little clunky and hard to fix if we add more languages later (or if one is missing).  Thus we will instruct Python to ask which files are available to us in the directory using the handy `listdir` function<sup>[[docs](https://docs.python.org/3/library/os.html#os.listdir)]</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afrikaans.txt', 'catalan.txt', 'danish.txt', 'english.txt', 'finnish.txt', 'french.txt', 'german.txt', 'latin.txt', 'polish.txt', 'portuguese.txt', 'spanish.txt', 'welsh.txt']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "languageNames = listdir('lang')\n",
    "print(languageNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop over the list `languageNames`, and for each language we can 1) create a dictionary using `load_ref` and 2) add this dictionary to the master dictionary `master` with the language as the key.  Do this in the function `loadLanguages` (which need have no parameters) and `return` `master`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "load_languages",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def load_languages():\n",
    "    # Create an empty dictionary `master`.\n",
    "    master = {}\n",
    "    \n",
    "    # Get a list of language files.\n",
    "    ## YOU WRITE THIS LINE (you can use the code block above as a starting point)\n",
    "    from os import listdir\n",
    "    languageNames = listdir('lang')\n",
    "    \n",
    "    # Call `load_ref` on each of these and add the resulting dictionary as a value to `master` with key `language`.\n",
    "    ## YOU WRITE THIS LOOP\n",
    "    for language in languageNames:\n",
    "        language = language[:-4]\n",
    "        language_freq = load_ref(language)\n",
    "        master[language] = language_freq\n",
    "    \n",
    "    # Finally, return the dict `master`.\n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['danish', 'latin', 'welsh', 'finnish', 'portuguese', 'german', 'spanish', 'french', 'catalan', 'english', 'polish', 'afrikaans']\n",
      "{'A': 0.09359999999999999, 'C': 0.028900000000000002, 'B': 0.0182, 'E': 0.08310000000000001, 'D': 0.09880000000000001, 'G': 0.0341, 'F': 0.031200000000000002, 'I': 0.0698, 'H': 0.0387, 'K': 0.0, 'J': 0.0013, 'M': 0.0248, 'L': 0.050300000000000004, 'O': 0.0559, 'N': 0.0812, 'Q': 0.0, 'P': 0.0091, 'S': 0.0291, 'R': 0.0652, 'U': 0.0258, 'T': 0.028399999999999998, 'W': 0.0398, 'V': 0.0, 'Y': 0.0849, 'X': 0.0, 'Z': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# test your code here.  You may edit this cell.\n",
    "master = load_languages()\n",
    "print(master.keys())\n",
    "print(master['welsh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_languages-test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_master = load_languages()\n",
    "assert isclose(test_master['english']['A'], 0.0834)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "load_languages-test2",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from numpy import isclose\n",
    "test_master = load_languages()\n",
    "assert isclose(test_master['catalan']['Z'], 0.001)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Predict the most likely language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `load_languages` and `calc_freq`, you are now prepared to assess the similarity of a text to a reference language.  This last step is the most mathematically involved.\n",
    "\n",
    "We will define a frequency metric $f$ to assess the closeness of the match between two sets of frequencies.  In human language, you will calculate the difference between the two lists $L_{\\text{unknown}}$ and $L_{\\text{ref}}$, which yields a third list of the differences.  To make this list positive, take its absolute value.  (This keeps equal but opposite errors from canceling each other out.)  To provide a single value to compare, let $f$ be equal to the sum of these absolute values.  Thus a low value of $f$ means a low difference and a better fit between two frequency distributions than a high value of $f$.  As an equation,\n",
    "\n",
    "$$\n",
    "f \\left( L_{\\text{text}}, L_{\\text{ref}} \\right) =\n",
    "\\sum_{\\text{letters}} \\left| L_{\\text{text}} - L_{\\text{ref}}\\right| \\text{.}\n",
    "$$\n",
    "\n",
    "To be clear, the metric we are calculating, $f$, is a metric for how *different* two letter frequency distributions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#FF8C00\">Exercises</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `calc_match` which accepts two dictionaries `L_text` and `L_ref`.  `calc_match` should return the calculated metric `f` according to the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['a'] = 1\n",
    "d['b'] = 3\n",
    "d.get('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "calc_match",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# define your function here\n",
    "def calc_match(L_text, L_ref):\n",
    "    # Create an empty dictionary `L_diff`.\n",
    "    L_diff = {}\n",
    "    \n",
    "    # Loop through the keys of the dictionaries (either by loading `alphabet` as above or by using `L_ref.keys()`).\n",
    "    # For sanity check: assert the key (letter) exist in both L_text and L_ref.\n",
    "    # Calculate the absolute value of the difference between each dictionary value for each letter\n",
    "    #     L_diff['A'] = abs(L_text['A'] - L_ref['A'])  # for each letter (or key in L_ref)\n",
    "    ## YOU WRITE THIS LOOP\n",
    "    for letter in L_text.keys():\n",
    "        assert (letter in L_text.keys()) and (letter in L_ref.keys())\n",
    "        L_diff[letter] = abs(L_text[letter] - L_ref[letter])\n",
    "    \n",
    "    # Next, loop through `L_diff` and sum all of the differences into the variable `f`.\n",
    "    f = 0.0\n",
    "    for letter in L_diff.keys():\n",
    "        f += L_diff[letter]\n",
    "    \n",
    "    # Finally, return the metric `f`.\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welsh, 0.348949\n"
     ]
    }
   ],
   "source": [
    "# test your code here.  You may edit this cell.\n",
    "text   = '''The conclusions of human reason as ordinarily applied in matters of nature, I call for the sake of distinction Anticipations of\n",
    "Nature (as a thing rash or premature). That reason which is elicited from facts by a just and methodical process, I call Interpretation of\n",
    "Nature.  (Francis Bacon, Novum Organon, Aphorism XXVI)'''\n",
    "L_text = calc_freq(text)\n",
    "master = load_languages()\n",
    "L_ref  = master['english']\n",
    "f = calc_match(L_text, L_ref)\n",
    "print('welsh, %f'%f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "surname_list-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test self-similarity and similarity across languages\n",
    "from numpy import isclose\n",
    "master = load_languages()\n",
    "assert isclose(calc_match(master['danish'], master['danish']), 0.0)\n",
    "assert isclose(calc_match(master['english'], master['finnish']), 0.5338)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "count_names-test2",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welsh, 0.348949\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "from numpy import isclose\n",
    "text   = '''The conclusions of human reason as ordinarily applied in matters of nature, I call for the sake of distinction Anticipations of\n",
    "Nature (as a thing rash or premature). That reason which is elicited from facts by a just and methodical process, I call Interpretation of\n",
    "Nature.  (Francis Bacon, Novum Organon, Aphorism XXVI)'''\n",
    "L_text = calc_freq(text)\n",
    "master = load_languages()\n",
    "L_ref  = master['english']\n",
    "f = calc_match(L_text, L_ref)\n",
    "print('welsh, %f'%f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#FF8C00\">Exercises</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will capture the above logic in a function `find_best_fit` which will accept a string `text` and a dictionary of reference language dictionaries `master`.  `find_best_fit` compares `text` against all languages in `master`.  `find_best_fit` will return the language corresponding to the lowest value of `f` across the different available reference languages.\n",
    "\n",
    "This is a freebie, so you can see the fruits of your labor in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "find_best_fit",
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This code already works---you don't need to write anything here.\n",
    "def find_best_fit(text, master):\n",
    "    # Create an empty dictionary `fs`.\n",
    "    fs = {}\n",
    "    \n",
    "    L_text = calc_freq(text)\n",
    "    \n",
    "    # Loop through the keys of `master` (by using `master.keys()`).\n",
    "    for language in master.keys():\n",
    "        # Calculate `f` for each using `calc_match` and store the result in `fs` with the key of the language.\n",
    "        L_ref = master[language]\n",
    "        fs[language] = calc_match(L_text, L_ref)\n",
    "    \n",
    "    # Finally, return the language corresponding to the minimum `f` in `fs` and the value of `f` in a tuple.\n",
    "    best_language = min(fs, key=fs.get)  # get the key with minimum value in `fs`\n",
    "    best_f = fs[best_language]\n",
    "    return (best_language, best_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fit for the text is *danish* with a metric of 0.174175.\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "text = '''\n",
    "    Soren Kierkegaard (\"Frygt og baven:  Dialektisk lyrik\", 1843)\n",
    "    Er det virkelig saa, er al den Spidsborgerlighed, jeg seer i Livet, som jeg ikke lader mit Ord men min Gjerning domme, er den virkelig\n",
    "    ikke hvad den synes, er den Vidunderet? Det lod sig jo tanke; thi hiin Troens Helt havde jo en paafaldende Lighed dermed; thi hiin Troens\n",
    "    Helt var end ikke Ironiker og Humorist, men noget endnu Hoiere. Der tales i vor Tid meget om Ironi og Humor, Lsær af Folk, som aldrig have\n",
    "    formaaet at praktisere deri, men som desuagtet vide at forklare Alt. Jeg er ikke ganske ubekjendt med disse tvende Lidenskaber, jeg veed\n",
    "    lidt mere om dem end hvad der staaer i tydske og tydsk-danske Compendier. Jeg veed derfor, at disse tvende Lidenskaber ere vasentlig\n",
    "    forskjellige fra Troens Lidenskab. Ironi og Humor reflektere ogsaa paa sig selv og hore derfor hjemme i den uendelige Resignations\n",
    "    Sphare, de have deres Elasticitet i, at Individet er incommensurabelt for Virkeligheden.\n",
    "    '''\n",
    "master = load_languages()\n",
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "find_best_fit-test",
     "locked": false,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# test success in counting name elements\n",
    "from numpy import isclose\n",
    "text = '''\n",
    "    Below the thunders of the upper deep;\n",
    "    Far, far beneath in the abysmal sea, \n",
    "    His ancient, dreamless, uninvaded sleep\n",
    "    The Kraken sleepeth: faintest sunlights flee\n",
    "    About his shadowy sides: above him swell\n",
    "    Huge sponges of millennial growth and height; \n",
    "    And far away into the sickly light, \n",
    "    From many a wondrous grot and secret cell\n",
    "    Unnumbered and enormous polypi\n",
    "    Winnow with giant arms the slumbering green.\n",
    "    There hath he lain for ages and will lie\n",
    "    Battening upon huge sea-worms in his sleep,\n",
    "    Until the latter fire shall heat the deep;\n",
    "    Then once by man and angels to be seen,\n",
    "    In roaring he shall rise and on the surface die.\n",
    "    (Alfred Lord Tennyson)\n",
    "    '''\n",
    "master = load_languages()\n",
    "language, f = find_best_fit(text, master)\n",
    "assert isclose(f, 0.198151072125)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most complex program you've yet written.  Let's take a survey of its overall logic:\n",
    "\n",
    "![](./img/flowchart.png)\n",
    "\n",
    "It's easy to get lost, but charting out your program's logic can help you navigate and think about coding challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The lab is now complete, but you may find it interesting to use this function to predict the language of the following text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = load_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Onder hierdie hoof wil ek u kortliks op grondige teëstelling wys en ook op verbinding. Die satiere, immers, is algemeen opgevat as\n",
    "spottende uiting van tenminste ontevredenheid of misnoeë ten opsigte van slegtheid en dwaasheid, bestaande wantoestande in die werklikheid,\n",
    "met die doel om daarteen gedagte, wil en gevoel op te wek. Hierby wil ek vooropstel die verskillende grade ven gevoel in satieriese spot,\n",
    "variërende tussen die uiterstes van hoon en sarkasme aan die een kant en gemoedelikheid van komiek en mildheid van humor aan die ander. 'n\n",
    "Definiesie van satiere wat enkel op hoon en bitterheid wys, skyn my egter nie ruim genoeg vir hierdie begrip nie. Hierteen kan miskien\n",
    "ingebring word dat ons dan die satiere nie langer in sy essensieelste vorm kry nie.  (F.E.J. Malherbe, Humor in die algemeen en sy uiting in\n",
    "die Afrikaanse letterkunde)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fit for the text is *afrikaans* with a metric of 0.149817.\n"
     ]
    }
   ],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst fit for the text is *welsh* with a metric of 0.572124.\n"
     ]
    }
   ],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Tots els essers humans neixen lliures i iguals en dignitat i en drets. Son dotats de rao i de consciencia, i han de comportar-se\n",
    "    fraternalment els uns amb els altres.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fit for the text is *french* with a metric of 0.277559.\n"
     ]
    }
   ],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst fit for the text is *polish* with a metric of 0.560747.\n"
     ]
    }
   ],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You will note that, unsurprisingly, short text samples are harder to statistically analyze in this manner.  The foregoing sample is written in Catalan, but this method detects a slightly different language.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Quoi que puisse dire Aristote, et toute la philosophie, il n'est rien d'eg\n",
    "al au tabac ; c'est la passion des honnetes gens ; et qui vit sans tabac n'es\n",
    "t pas digne de vivre. Non seulement il rejouit et purge les cerveaux huma\n",
    "ins, mais encore il instruit les ames a la vertu, et l'on apprend avec lui a deve\n",
    "nir honnete homme. Ne voyez-vous pas bien, des qu'on en prend, de quelle mani\n",
    "ere obligeante on en use avec tout le monde, et comme on est ravi d'en donn\n",
    "er a droite et a gauche, partout ou l'on se trouve ? On n'attend pas meme qu'o\n",
    "n en demande, et l'on court au-devant du souhait des gens ; tant il est vrai que\n",
    "le tabac inspire des sentiments d'honneur et de vertu a tous ceux qui en pren\n",
    "nent. Mais c'est assez de cette matiere, reprenons un peu notre discours. Si bien\n",
    " donc, cher Gusman, que done Elvire, ta maitresse, surprise de notre depart, s'es\n",
    "t mise en campagne apres nous ; et son coeur, que mon Maitre a su toucher trop\n",
    " fortement, n'a pu vivre, dis-tu, sans le venir chercher ici. Veux-tu qu'e\n",
    "ntre-nous je te dise ma pensee ? J'ai peur qu'elle ne soit mal payee de son amou\n",
    "r, que son voyage en cette ville produise peu de fruit, et que vous eussiez auta\n",
    "nt gagne a ne bouger de la.\n",
    "\n",
    "(Moliere, Don Juan ou le Festin de pierre)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fit for the text is *french* with a metric of 0.162854.\n"
     ]
    }
   ],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst fit for the text is *welsh* with a metric of 0.653765.\n"
     ]
    }
   ],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
    "tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua,\n",
    "rocin flaco y galgo corredor. Una olla de algo mas vaca que carnero,\n",
    "salpicon las mas noches, duelos y quebrantos los sabados, lantejas los\n",
    "viernes, algun palomino de anadidura los domingos, consumían las tres\n",
    "partes de su hacienda. El resto della concluian sayo de velarte, calzas de\n",
    "velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias de\n",
    "entresemana se honraba con su vellori de lo mas fino. Tenia en su casa una\n",
    "ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte,\n",
    "y un mozo de campo y plaza, que asi ensillaba el rocin como tomaba la\n",
    "podadera. Frisaba la edad de nuestro hidalgo con los cincuenta anos; era de\n",
    "complexion recia, seco de carnes, enjuto de rostro, gran madrugador y amigo\n",
    "de la caza. Quieren decir que tenia el sobrenombre de Quijada, o Quesada,\n",
    "que en esto hay alguna diferencia en los autores que deste caso escriben;\n",
    "aunque, por conjeturas verosimiles, se deja entender que se llamaba\n",
    "Quejana. Pero esto importa poco a nuestro cuento; basta que en la narracion\n",
    "del no se salga un punto de la verdad.\n",
    "(Miguel de Saavedra Cervantes, Don Quixote)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the best match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best fit for the text is *spanish* with a metric of 0.145452.\n"
     ]
    }
   ],
   "source": [
    "language, f = find_best_fit(text, master)\n",
    "print('The best fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Which language is the worst match, and its value of $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst fit for the text is *welsh* with a metric of 0.548099.\n"
     ]
    }
   ],
   "source": [
    "fs = {}\n",
    "L_text = calc_freq(text)\n",
    "for language in master.keys():\n",
    "    fs[language] = calc_match(L_text, master[language])\n",
    "\n",
    "language = max(fs, key=fs.get)  # calculate the maximum value of any key in `fs`\n",
    "f = fs[language]\n",
    "print('The worst fit for the text is *%s* with a metric of %f.'%(language,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! This is all we have for today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
